{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Tracking\n",
    "\n",
    "- **Instructor**: Jongwoo Lim / Jiun Bae\n",
    "- **Email**: [jlim@hanyang.ac.kr](mailto:jlim@hanyang.ac.kr) / [jiunbae.623@gmail.com](mailto:jiunbae.623@gmail.com)\n",
    "\n",
    "## Object Tracking (MDNet)\n",
    "\n",
    "Object Tracking is tracking object in consecutive image sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem in tracking\n",
    "\n",
    "Visual tracking problems. In traditional approach, tracking using hand-crafted features.\n",
    "\n",
    "![tracking-prablem](../assets/tracking-problem.png)\n",
    "\n",
    "Lack of data for visual tracking. Beacuse image sequences has different domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDNet\n",
    "\n",
    "Shared layers and domain-specific layers each domain in trained separately.\n",
    "\n",
    "![MDNet](../assets/MDNet.png)\n",
    "\n",
    "MDNet tactics:\n",
    "\n",
    "1. Bounding box regression\n",
    "2. Hard negative mining\n",
    "3. Consider long-term and short-term changes\n",
    "\n",
    "![MDNet-Regression](../assets/MDNet-regression.png)\n",
    "![MDNet-HardNegativeMining](../assets/MDNet-hardnegative.png)\n",
    "![MDNet-Short-Long-Term](../assets/MDNet-long-short-term.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online tracking (at inference)\n",
    "\n",
    "Drop all domain-specific layers, attach new randomly initilized branch.\n",
    "Update when first frame given.\n",
    "\n",
    "![MDNet-online](../assets/MDNet-inference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "First of all, Import some packages for using PyTorch.\n",
    "\n",
    "- torch.nn: The **Network** of PyTorch basically starts with nn.Module.\n",
    "- torch.nn.functional: for **Functions** such as *ReLU*, *MaxPool* (in this example)\n",
    "- torch.optim: for **Optimizers**\n",
    "- torchvision: Handling **Datasets**\n",
    "\n",
    "Numpy the basic scientific computing package used in customary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from MDNet.models.mdnet import MDNet, BCELoss, Precision\n",
    "from MDNet.models.extractor import SampleGenerator, RegionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "OTBDownload OTB-50, 100 dataset from [CVLab](http://cvlab.hanyang.ac.kr/tracker_benchmark/datasets.html).\n",
    "\n",
    "![OTB-100](../assets/OTB.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, root: str, options):\n",
    "        self.sequences, self.images, self.ground_truths = map(list, zip(*[(\n",
    "            str(seq.stem),\n",
    "            list(map(str, sorted(seq.glob('img/*.jpg')))),\n",
    "            pd.read_csv(str(seq.joinpath('groundtruth_rect.txt')), header=None, sep=r'\\,|\\t|\\ ', engine='python').values,\n",
    "        ) for seq in filter(lambda p: p.is_dir(), Path(root).iterdir())]))\n",
    "        \n",
    "        # assertion\n",
    "        for i, _ in enumerate(self.sequences):\n",
    "            if len(self.images[i]) != np.size(self.ground_truths[i], 0):\n",
    "                self.images[i] = self.images[i][:self.ground_truths[i].shape[0]]\n",
    "        \n",
    "        self.regions = [RegionDataset(i, g, options) for i, g in zip(self.images, self.ground_truths)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.regions[idx]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from self.regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = yaml.safe_load(open('MDNet/options.yaml','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('../data/OTB', opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MDNet(opts['init_model_path'], len(dataset)).to(device)\n",
    "model.set_learnable_params(opts['ft_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCELoss()\n",
    "evaluator = Precision()\n",
    "optimizer = model.optimizer(opts['lr'], opts['lr_mult'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(opts['n_cycles']):\n",
    "    model.train()\n",
    "    \n",
    "    prec = np.zeros(len(dataset))\n",
    "    permute = np.random.permutation(len(dataset))\n",
    "\n",
    "    for i, j in enumerate(permute):\n",
    "        pos, neg = dataset[j].next()\n",
    "        \n",
    "        pos_loss = model(pos.to(device), j)\n",
    "        neg_loss = model(neg.to(device), j)\n",
    "        \n",
    "        loss = criterion(pos_loss, neg_loss)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        if 'grad_clip' in opts:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opts['grad_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        prec[j] = evaluator(pos_loss, neg_loss)\n",
    "        \n",
    "        if not i % 10:\n",
    "            print(f'Iter {i:2d} (Domain {j:2d}), Loss {loss.item():.3f}, Precision {prec[j]:.3f}')\n",
    "\n",
    "    print(f'Batch {b:2d}: Mean Precision: {prec.mean():.3f}')\n",
    "    \n",
    "    torch.save({\n",
    "        'shared_layers': model.cpu().layers.state_dict()\n",
    "    }, opts['model_path'])\n",
    "    \n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from MDNet.utils import Options, overlap_ratio\n",
    "from MDNet.models.extractor import RegionExtractor\n",
    "from MDNet.models.regressor import BBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_samples(model, image, samples, opts, out_layer='conv3'):\n",
    "    model.eval()\n",
    "    extractor = RegionExtractor(image, samples, opts.img_size, opts.padding, opts.batch_test)\n",
    "\n",
    "    for i, regions in enumerate(extractor):\n",
    "        if opts.use_gpu:\n",
    "            regions = regions.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat = model(regions, out_layer=out_layer)\n",
    "\n",
    "        feats = torch.cat((feats, feat.detach().clone()), 0) if i else feat.detach().clone()\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer,\n",
    "          pos_feats, neg_feats, maxiter, opts,\n",
    "          in_layer='fc4'):\n",
    "    model.train()\n",
    "\n",
    "    batch_pos = opts.batch_pos\n",
    "    batch_neg = opts.batch_neg\n",
    "    batch_test = opts.batch_test\n",
    "    batch_neg_cand = max(opts.batch_neg_cand, batch_neg)\n",
    "\n",
    "    pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "    neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "\n",
    "    while len(pos_idx) < batch_pos * maxiter:\n",
    "        pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "\n",
    "    while len(neg_idx) < batch_neg_cand * maxiter:\n",
    "        neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "\n",
    "    pos_pointer = 0\n",
    "    neg_pointer = 0\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "\n",
    "        # select pos idx\n",
    "        pos_next = pos_pointer + batch_pos\n",
    "        pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "        pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "        pos_pointer = pos_next\n",
    "\n",
    "        # select neg idx\n",
    "        neg_next = neg_pointer + batch_neg_cand\n",
    "        neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "        neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "        neg_pointer = neg_next\n",
    "\n",
    "        # create batch\n",
    "        batch_pos_feats = pos_feats[pos_cur_idx]\n",
    "        batch_neg_feats = neg_feats[neg_cur_idx]\n",
    "\n",
    "        # hard negative mining\n",
    "        if batch_neg_cand > batch_neg:\n",
    "            model.eval()\n",
    "\n",
    "            for start in range(0, batch_neg_cand, batch_test):\n",
    "                end = min(start + batch_test, batch_neg_cand)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    score = model(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "\n",
    "                if start == 0:\n",
    "                    neg_cand_score = score.detach()[:, 1].clone()\n",
    "                else:\n",
    "                    neg_cand_score = torch.cat((neg_cand_score, score.detach()[:, 1].clone()), 0)\n",
    "\n",
    "            _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "            batch_neg_feats = batch_neg_feats[top_idx]\n",
    "            model.train()\n",
    "\n",
    "        # forward\n",
    "        pos_score = model(batch_pos_feats, in_layer=in_layer)\n",
    "        neg_score = model(batch_neg_feats, in_layer=in_layer)\n",
    "\n",
    "        # optimize\n",
    "        loss = criterion(pos_score, neg_score)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), opts.grad_clip)\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(images, init_bbox, ground_truths, opts):\n",
    "    device = ('cuda' if opts.use_gpu else 'cpu')\n",
    "\n",
    "    model = MDNet(opts.model_path).to(device)\n",
    "\n",
    "    criterion = BCELoss()\n",
    "\n",
    "    # Set learnable parameters\n",
    "    for k, p in model.params.items():\n",
    "        p.requires_grad = any([k.startswith(l) for l in opts.ft_layers])\n",
    "\n",
    "    # Set optimizer states\n",
    "    def set_optimizer(lr_base, lr_mult, momentum=0.9, w_decay=0.0005):\n",
    "        param_list = []\n",
    "\n",
    "        for k, p in filter(lambda kp: kp[1].requires_grad, model.params.items()):\n",
    "            lr = lr_base\n",
    "            for l, m in lr_mult.items():\n",
    "                if k.startswith(l):\n",
    "                    lr = lr_base * m\n",
    "            param_list.append({'params': [p], 'lr': lr})\n",
    "\n",
    "        return optim.SGD(param_list, lr=lr, momentum=momentum, weight_decay=w_decay)\n",
    "\n",
    "    init_optimizer = set_optimizer(opts.lr_init, opts.lr_mult)\n",
    "    update_optimizer = set_optimizer(opts.lr_update, opts.lr_mult)\n",
    "\n",
    "    # Load first image\n",
    "    image = Image.open(images[0]).convert('RGB')\n",
    "\n",
    "    # Draw pos/neg samples\n",
    "    pos_examples = SampleGenerator('gaussian', image.size, opts.trans_pos, opts.scale_pos)(\n",
    "        init_bbox, opts.n_pos_init, opts.overlap_pos_init)\n",
    "\n",
    "    neg_examples = np.concatenate([\n",
    "        SampleGenerator('uniform', image.size, opts.trans_neg_init, opts.scale_neg_init)(\n",
    "            init_bbox, int(opts.n_neg_init * 0.5), opts.overlap_neg_init),\n",
    "        SampleGenerator('whole', image.size)(\n",
    "            init_bbox, int(opts.n_neg_init * 0.5), opts.overlap_neg_init)])\n",
    "    neg_examples = np.random.permutation(neg_examples)\n",
    "\n",
    "    # Extract pos/neg features\n",
    "    pos_feats = forward_samples(model, image, pos_examples, opts)\n",
    "    neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "\n",
    "    # Initial training\n",
    "    train(model, criterion, init_optimizer, pos_feats, neg_feats, opts.maxiter_init, opts)\n",
    "    del init_optimizer, neg_feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Train bbox regressor\n",
    "    bbreg_examples = SampleGenerator('uniform', image.size, opts.trans_bbreg, opts.scale_bbreg, opts.aspect_bbreg)\\\n",
    "        (init_bbox, opts.n_bbreg, opts.overlap_bbreg)\n",
    "\n",
    "    bbreg_feats = forward_samples(model, image, bbreg_examples, opts)\n",
    "    bbreg = BBRegressor(image.size)\n",
    "    bbreg.train(bbreg_feats, bbreg_examples, init_bbox)\n",
    "    del bbreg_feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Init sample generators for update\n",
    "    sample_generator = SampleGenerator('gaussian', image.size, opts.trans, opts.scale)\n",
    "    pos_generator = SampleGenerator('gaussian', image.size, opts.trans_pos, opts.scale_pos)\n",
    "    neg_generator = SampleGenerator('uniform', image.size, opts.trans_neg, opts.scale_neg)\n",
    "\n",
    "    # Init pos/neg features for update\n",
    "    neg_examples = neg_generator(init_bbox, opts.n_neg_update, opts.overlap_neg_init)\n",
    "    neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "    pos_feats_all = [pos_feats]\n",
    "    neg_feats_all = [neg_feats]\n",
    "\n",
    "    # Main loop\n",
    "    for i, image in enumerate(images[1:], 1):\n",
    "        image = Image.open(image).convert('RGB')\n",
    "\n",
    "        # Estimate target bbox\n",
    "        samples = sample_generator(init_bbox, opts.n_samples)\n",
    "        sample_scores = forward_samples(model, image, samples, opts, out_layer='fc6')\n",
    "\n",
    "        top_scores, top_idx = sample_scores[:, 1].topk(5)\n",
    "        top_idx = top_idx.cpu()\n",
    "        target_score = top_scores.mean()\n",
    "        init_bbox = samples[top_idx]\n",
    "        if top_idx.shape[0] > 1:\n",
    "            init_bbox = init_bbox.mean(axis=0)\n",
    "        success = target_score > 0\n",
    "\n",
    "        # Expand search area at failure\n",
    "        sample_generator.trans = opts.trans if success else min(sample_generator.trans * 1.1, opts.trans_limit)\n",
    "\n",
    "        # Bbox regression\n",
    "        if success:\n",
    "            bbreg_samples = samples[top_idx]\n",
    "\n",
    "            if top_idx.shape[0] == 1:\n",
    "                bbreg_samples = bbreg_samples[None, :]\n",
    "\n",
    "            bbreg_feats = forward_samples(model, image, bbreg_samples, opts)\n",
    "            bbreg_samples = bbreg.predict(bbreg_feats, bbreg_samples)\n",
    "            bbreg_bbox = bbreg_samples.mean(axis=0)\n",
    "\n",
    "        else:\n",
    "            bbreg_bbox = init_bbox\n",
    "\n",
    "        yield init_bbox, bbreg_bbox, overlap_ratio(ground_truths[i], bbreg_bbox)[0], target_score\n",
    "\n",
    "        # Data collect\n",
    "        if success:\n",
    "            pos_examples = pos_generator(init_bbox, opts.n_pos_update, opts.overlap_pos_update)\n",
    "            pos_feats = forward_samples(model, image, pos_examples, opts)\n",
    "            pos_feats_all.append(pos_feats)\n",
    "\n",
    "            if len(pos_feats_all) > opts.n_frames_long:\n",
    "                del pos_feats_all[0]\n",
    "\n",
    "            neg_examples = neg_generator(init_bbox, opts.n_neg_update, opts.overlap_neg_update)\n",
    "            neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "            neg_feats_all.append(neg_feats)\n",
    "\n",
    "            if len(neg_feats_all) > opts.n_frames_short:\n",
    "                del neg_feats_all[0]\n",
    "\n",
    "        # Short term update\n",
    "        if not success:\n",
    "            nframes = min(opts.n_frames_short, len(pos_feats_all))\n",
    "            pos_data = torch.cat(pos_feats_all[-nframes:], 0)\n",
    "            neg_data = torch.cat(neg_feats_all, 0)\n",
    "            train(model, criterion, update_optimizer, pos_data, neg_data, opts.maxiter_update, opts)\n",
    "\n",
    "        # Long term update\n",
    "        elif i % opts.long_interval == 0:\n",
    "            pos_data = torch.cat(pos_feats_all, 0)\n",
    "            neg_data = torch.cat(neg_feats_all, 0)\n",
    "            train(model, criterion, update_optimizer, pos_data, neg_data, opts.maxiter_update, opts)\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.use_gpu = False\n",
    "options.model_path = \"../data/mdnet_otb.pth\"\n",
    "dataset = Path('../data/OTB/DragonBaby')\n",
    "\n",
    "images = list(sorted(dataset.joinpath('img').glob('*.jpg')))\n",
    "ground_truths = pd.read_csv(str(dataset.joinpath('groundtruth_rect.txt')), header=None).values\n",
    "\n",
    "iou, success = 0, 0\n",
    "\n",
    "# Run tracker\n",
    "for i, (result, (x, y, w, h), overlap, score) in \\\n",
    "        enumerate(main(images, ground_truths[0], ground_truths, options), 1):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    image = np.asarray(Image.open(images[i]).convert('RGB'))\n",
    "\n",
    "    gx, gy, gw, gh = ground_truths[i]\n",
    "    cv2.rectangle(image, (int(gx), int(gy)), (int(gx+gw), int(gy+gh)), (0, 255, 0), 2)\n",
    "    cv2.rectangle(image, (int(x), int(y)), (int(x+w), int(y+h)), (255, 0, 0), 2)\n",
    "\n",
    "    iou += overlap\n",
    "    success += overlap > .5\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.pause(.1)\n",
    "    plt.title(f'#{i}/{len(images)-1}, Overlap {overlap:.3f}, Score {score:.3f}')\n",
    "    plt.draw()\n",
    "\n",
    "iou /= len(images) - 1\n",
    "print(f'Mean IOU: {iou:.3f}, Success: {success} / {len(images)-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
