{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Example\n",
    "\n",
    "- **Instructor**: Jongwoo Lim / Jiun Bae\n",
    "- **Email**: [jlim@hanyang.ac.kr](mailto:jlim@hanyang.ac.kr) / [jiunbae.623@gmail.com](mailto:jiunbae.623@gmail.com)\n",
    "\n",
    "## Image classification with RNN\n",
    "\n",
    "We can use RNN using image classification. Flatten image pixels as 1-D sequential array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "First of all, Import some packages for using PyTorch.\n",
    "\n",
    "- torch.nn: The **Network** of PyTorch basically starts with nn.Module.\n",
    "- torch.nn.functional: for **Functions** such as *ReLU*, *MaxPool* (in this example)\n",
    "- torch.optim: for **Optimizers**\n",
    "- torchvision: Handling **Datasets**\n",
    "\n",
    "Numpy the basic scientific computing package used in customary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "PyTorch basically provides MNIST Dataset and support download in running code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '../data' # path to download mnist dataset\n",
    "\n",
    "TRAIN_DATASET = datasets.MNIST(DATASET_DIR,   # Dataset root path\n",
    "                               train=True,    # Train data\n",
    "                               download=True) # Download if not exist\n",
    "\n",
    "TEST_DATASET = datasets.MNIST(DATASET_DIR,    # Dataset root path\n",
    "                              train=False)    # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "def show(ary):\n",
    "    display(Image.fromarray(ary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = TRAIN_DATASET[0]\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(image.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run!\n",
    "\n",
    "\n",
    "### Reproducible (**Important**)\n",
    "\n",
    "**Reproducible** is very **very** ***very*** important in experiment. An experiment that can not be reproduced can not make any conclusions. So fix random seed before anything else.\n",
    "In **PyTorch** just call `torch.manual_seed` for fix random seed. It will set the seed of the random generator, so random results will be **reproducible**.\n",
    "\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Unfortunately, machine learning does not mean learning all the variables. We call these parameters the **hyperparameters** that need to be set before learning.\n",
    "In this example, we can set the *learning rate* before training.\n",
    "\n",
    "\n",
    "### DataLoader\n",
    "\n",
    "Loading files from disk is a very expensive operation. Especially in machine learning where a lot of training data is needed, also especially if each data is an image.\n",
    "So, many frameworks provide *data loader* for effectively load data such as use multiple threads and cache. In **PyTorch** DataLoader support shuffle, batch slice, transform and many other functions.\n",
    "But in this example, just use `batch_size` and `shuffle`.\n",
    "\n",
    "PyTorch only process `torch.Tensor`. So, must convert data (3d numpy array) to tensor (torch.Tensor) using transform before training(or test).\n",
    "*`transforms.ToTensor()` automatically transform data to tensor when loader called*\n",
    "\n",
    "\n",
    "### GPU or CPU\n",
    "\n",
    "`device` variable use **CUDA** if available. CPU can get results fast enough because there are fewer data and the network is simple. But when more data is available and the network gets more complicated, it's time to get help from the GPU. So now you do not have to worry.\n",
    "Later `.to (device)` means use the device we specified.\n",
    "\n",
    "\n",
    "### Build Network\n",
    "\n",
    "`model = Network()` create network we defined before. In this example, we use [SGD(Stochastic gradient descent)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # 42, THE ANSWER TO LIFE, THE UNIVERSE AND EVERYTHING\n",
    "\n",
    "batch = 16            # batch size\n",
    "lr = .1              # learning rate\n",
    "epochs = 16\n",
    "\n",
    "\n",
    "TRAIN_DATASET.transform = transforms.ToTensor()\n",
    "train_loader = torch.utils.data.DataLoader(TRAIN_DATASET,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "TEST_DATASET.transform = transforms.ToTensor()\n",
    "test_loader = torch.utils.data.DataLoader(TEST_DATASET,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, 1, bias=True, batch_first=True, \n",
    "                          nonlinearity='tanh', dropout=0)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        out, states = self.rnn(inputs, states)\n",
    "        out = self.fc(out)\n",
    "        out = F.log_softmax(out, dim=-1)\n",
    "        return out, states\n",
    "\n",
    "    def state(self, _batch):\n",
    "        # return initialized hidden state\n",
    "        return torch.zeros(1, _batch, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET.transform = transforms.ToTensor()\n",
    "train_loader = torch.utils.data.DataLoader(TRAIN_DATASET,\n",
    "                                           batch_size=batch,\n",
    "                                           shuffle=True)\n",
    "\n",
    "TEST_DATASET.transform = transforms.ToTensor()\n",
    "test_loader = torch.utils.data.DataLoader(TEST_DATASET,\n",
    "                                          batch_size=batch,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        image = image.view(-1, 1, input_size).to(device)\n",
    "        label = label.to(device)\n",
    "        out, state = model(image, model.state(batch))\n",
    "        loss += criterion(out.squeeze(), label)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if not (epoch % 2):\n",
    "        model.eval()\n",
    "        print(f'Loss: {loss.item()}')\n",
    "        for image, label in test_loader:\n",
    "            image = image.view(-1, 1, input_size).to(device)\n",
    "            label = label.to(device)\n",
    "            out, state = model(image, model.state(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for _, (image, label) in zip(range(5), TEST_DATASET):\n",
    "    image = image.view(-1, 1, input_size).to(device)\n",
    "    out, _ = model(image, model.state(1))\n",
    "    \n",
    "    show((image.detach().cpu().numpy().reshape(28, 28) * 255).astype(np.uint8))\n",
    "    print(f'Label: {label}, prediction: {out.argmax()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
