{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각 심화\n",
    "\n",
    "- **Instructor**: Jongwoo Lim / Jiun Bae\n",
    "- **Email**: [jlim@hanyang.ac.kr](mailto:jlim@hanyang.ac.kr) / [jiunbae.623@gmail.com](mailto:jiunbae.623@gmail.com)\n",
    "\n",
    "## NeuralNetwork Example\n",
    "\n",
    "In this example you will practice a simple neural network written by only [Numpy](https://www.numpy.org) which is fundamental package for scientific computing with Python. The goals of this example are as follows:\n",
    "\n",
    "- Understand **Neural Networks** and how they work.\n",
    "- Learn basically how to **write and use code**(*Numpy*).\n",
    "\n",
    "*If you are more familiar with PyTorch and TensorFlow(or Keras), You might be wondering why to write from the ground up with numpy instead of the built-in framework. This process is essential for understanding how a neural network works, and if you understand it, will not be too difficult to write in code.*\n",
    "\n",
    "And this example also is written in [IPython Notebook](https://ipython.org/notebook.html), an interactive computational environment, in which you can run code directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments\n",
    "\n",
    "In this assignment, we assume the follows environments. \n",
    "\n",
    "The [Python](https://www.python.org) is a programming language that lets you work quickly and integrate systems more effectively. It is widely used in various fields, and also used in machine learning.\n",
    "\n",
    "The [Pytorch](https://pytorch.org) is an open source deep learning platform, provides a seamless path from research to production.\n",
    "\n",
    "The [Tensorflow](https://www.tensorflow.org) is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.\n",
    "\n",
    "The [CUDA®](https://developer.nvidia.com/cuda-zone) Toolkit provides high-performance GPU-accelerated computation. In deep learning, the model takes an age to train without GPU-acceleration. ~~even with the GPU, it still takes a lot of time~~.\n",
    "\n",
    "\n",
    "- [Python3](https://www.python.org/downloads/) (recommend 3.6 or above)\n",
    "- [PyTorch](https://pytorch.org) (recommend 1.0)\n",
    "- [Tensorflow](https://tensorflow.org) (recommend above 1.13.0, but under 2.0 *There are huge difference between 2.0 and below*)\n",
    "- [NumPy](http://www.numpy.org) the fundamental package for scientific computing with Python\n",
    "\n",
    "\n",
    "- (Optional) [Anaconda](https://www.anaconda.com/distribution/#download-section), *popular Python Data Science Platform*\n",
    "- (Optional) [Jupyter](https://jupyter.org/) (Notebook or Lab)\n",
    "- (Optional) [CUDA](https://developer.nvidia.com/cuda-downloads) support GPU\n",
    "\n",
    "\n",
    "Python packages can install by `pip install [package name]` or using **Anaconda** by `conda install [package name]`.\n",
    "\n",
    "*If you are having trouble installing or something else, please contact TA or jiun.maydev@gmail.com.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "Numpy the basic scientific computing package used in customary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST dataset\n",
    "\n",
    "Tesnorflow provide mnist dataset as binary archive file [link](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.7/tensorflow/g3doc/tutorials/mnist/download/index.md).\n",
    "In this exampe, we already downloaded datafile in `./data` directory. So just laod dataset from `./data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/MNIST/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = idx2numpy.convert_from_file(str(data_dir.joinpath('train-images-idx3-ubyte')))\n",
    "train_labels = idx2numpy.convert_from_file(str(data_dir.joinpath('train-labels-idx1-ubyte')))\n",
    "test_images = idx2numpy.convert_from_file(str(data_dir.joinpath('t10k-images-idx3-ubyte')))\n",
    "test_labels = idx2numpy.convert_from_file(str(data_dir.joinpath('t10k-labels-idx1-ubyte')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "def show(ary):\n",
    "    display(Image.fromarray(ary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label, _ in zip(train_images, train_labels, range(10)):\n",
    "    print(label)\n",
    "    show(image.reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255. We scale these values to a range of 0 to 1 before feeding to the neural network model. For this, we divide the values by 255. It's important that the training set and the testing set are preprocessed in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "train_images = train_images / 255.\n",
    "test_images = test_images / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = np.eye(num_classes)[train_labels]\n",
    "test_labels = np.eye(num_classes)[test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "This is a simple two dense(fully connected) layer network. The code is quite easy.\n",
    "\n",
    "So, whole network architecture as follow:\n",
    "\n",
    "- Dense\n",
    "- Sigmoid\n",
    "- Dense\n",
    "- Sigmoid\n",
    "- Dense\n",
    "- Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    pass\n",
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units):\n",
    "        self.weights = np.random.randn(output_units, input_units) * .01\n",
    "        self.biases = np.random.randn(output_units, 1) * .1\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        return np.dot(self.weights, inputs) + self.biases\n",
    "      \n",
    "    def backward(self, grads):\n",
    "        size = np.size(grads, -1)\n",
    "\n",
    "        self.grad_weights = np.dot(grads, self.inputs.T) / size\n",
    "        self.grad_biases = np.sum(grads, axis=1, keepdims=True) / size\n",
    "\n",
    "        return np.dot(self.weights.T, grads)\n",
    "\n",
    "    def update(self, lr: float = .01):\n",
    "        # Here we perform a stochastic gradient descent step.\n",
    "        self.weights = self.weights - lr * self.grad_weights\n",
    "        self.biases = self.biases - lr * self.grad_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate Function: Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return 1. / (1. + np.exp(-inputs))\n",
    "\n",
    "    def backward(self, grads):\n",
    "        r = self.forward(self.inputs)\n",
    "        return grads * r * (1. - r)\n",
    "    \n",
    "    def update(self, lr):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def fit(networks: List[Layer], X, y, train=True, epsilon=1e-7):\n",
    "    X = np.reshape(X, (X.shape[0], -1))\n",
    "    \n",
    "    # Forward\n",
    "    preds = reduce(lambda inputs, layer: layer.forward(inputs), [X.T, *networks]).T\n",
    "    \n",
    "    # Compute Loss\n",
    "    loss = -np.sum(y * np.log(np.clip(preds, epsilon, 1. - epsilon) + epsilon)) / np.size(preds, 0)\n",
    "    \n",
    "    if train:\n",
    "        # Backward\n",
    "        grads = -(np.divide(y, preds) - np.divide(1 - y, 1 - preds))\n",
    "        grads = reduce(lambda grads, layer: layer.backward(grads), [grads.T, *reversed(networks)])\n",
    "    \n",
    "        # Update\n",
    "        for layer in networks:\n",
    "            layer.update(lr)\n",
    "    \n",
    "    return loss.mean(), preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(datasets, batch):\n",
    "    image, label = None, None\n",
    "    images, labels = datasets\n",
    "    for b, (i, l) in enumerate(zip(*datasets)):\n",
    "        if not (b % batch):\n",
    "            if image is not None and label is not None:\n",
    "                yield image, label\n",
    "            image = np.empty((batch, 28, 28, 1), dtype=np.float32)\n",
    "            label = np.empty((batch, 10), dtype=np.uint8)\n",
    "            \n",
    "        image[b % batch] = i\n",
    "        label[b % batch] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .1\n",
    "batch = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "    Dense(28*28, 10),\n",
    "    Sigmoid(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Train scope\n",
    "    train_loss, test_loss, test_acc = 0, 0, 0\n",
    "    for images, labels in get_batch((train_images, train_labels), batch):\n",
    "        loss, _ = fit(network, images, labels)\n",
    "        train_loss += loss\n",
    "        \n",
    "    for images, labels in get_batch((test_images, test_labels), batch):\n",
    "        loss, preds = fit(network, images, labels, train=False)\n",
    "\n",
    "        test_loss += loss\n",
    "        test_acc += (preds.argmax(axis=-1) == labels.argmax(axis=-1)).mean()\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\tTrain Loss: {train_loss / (len(train_images) / batch)}')\n",
    "    print(f'\\tTest Loss: {test_loss / (len(test_images) / batch)}')\n",
    "    print(f'\\tTest Acc: {test_acc / (len(test_images) / batch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label, _ in zip(test_images, test_labels, range(10)):\n",
    "    show((image[:, :, 0] * 255.).astype(np.uint8))\n",
    "    prediction = reduce(lambda inputs, layer: layer.forward(inputs), [np.reshape(np.array(image), -1)[None, :].T, *network])\n",
    "    print (f'Label: {label.argmax(-1)}, Prediction: {prediction.argmax()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. More complex model\n",
    "\n",
    "We can create more complex models by adding layers to the network.\n",
    "\n",
    "What makes the next model(*two-dense-layer*) different from the previous model with one layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "    Dense(28*28, 128),\n",
    "    Sigmoid(),\n",
    "    Dense(128, 10),\n",
    "    Sigmoid(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. What is activation function?\n",
    "\n",
    "What is the role of the Sigmoid in the middle? If not, what would happen?\n",
    "\n",
    "What other functions will replace Sigmoid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "    Dense(28*28, 128),\n",
    "    Dense(128, 10),\n",
    "    Sigmoid(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. And then more, more, more ... layers?\n",
    "\n",
    "What will happen if you stack a lot of layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "    Dense(28*28, 600),\n",
    "    Sigmoid(),\n",
    "    Dense(600, 500),\n",
    "    Sigmoid(),\n",
    "    Dense(500, 400),\n",
    "    Sigmoid(),\n",
    "    Dense(400, 300),\n",
    "    Sigmoid(),\n",
    "    Dense(300, 200),\n",
    "    Sigmoid(),\n",
    "    Dense(200, 100),\n",
    "    Sigmoid(),\n",
    "    Dense(100, 10),\n",
    "    Sigmoid(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Parameters\n",
    "\n",
    "Check the size of the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof(model):\n",
    "    return sum(getattr(layer, attr, np.empty(0)).size for attr in ['weights', 'bias'] for layer in model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
